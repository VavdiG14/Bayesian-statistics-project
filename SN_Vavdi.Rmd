---
title: "Bayesova statisika"
subtitle: "Seminarska naloga"
author: "Gregor Vavdi"
date: "1/3/2020"
fontsize: 12pt
output:
  pdf_document:
    number_sections: yes
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(plyr)
library(dplyr)
library(tidyr)
library(MASS)
library(abe)
library(nimble)
library(R2BayesX)
library(data.table)
library(R2BayesX)
library(dplyr)
library(car)
library(kableExtra)
library(nimble)
library(basicMCMCplots)
library(coda)
library(ggplot2)
dt <- readRDS("data/podatkiRAK.RDS")
samples <- readRDS("data/HieMod.RDS")
samples.thinning <- readRDS("data/HieMod_thinning.RDS")
samples.mixing <- readRDS("data/HieMod_vec_verig.RDS")
dt$RefIso <- factor(dt$RefIso,labels = c("Glava", "Vrat"))
povprecje.pacientov <- dt %>% group_by(AnonId) %>% summarise(st.frakcij = n()) 
podatki.st.frakcij <- dt %>% left_join(povprecje.pacientov,by = c("AnonId")) 
```

# Primerjava frekventističnega in Bayesovega pristopa pri linearni regersiji

## Cilj

Linearna regerisja je eno najbolj osnovnih statističnih orodij. V zadnjem času  prihaja do porasta tudi v Bayesovi statistiki. V tej nalogi bom simuliral različne vrste podatkov, pri čemer me je zanimala predvsem razlika v klasičnem (frekvetističnem) prisotpu in Bayesovem pristopu. Podatke sem generiral z namenom, da me bosta zanimala predvsem kako vrsta slučajne napakez vpliva na pristopa in korelacija med podatki. 

## Opis simulacije

Simulacijo sem si zamislil na naslednji način. Najprej generiramo podatke, nato pa na istih podatkih apliciramo oba pristopa linearne regresije. To sem ponovil 1000x in nato pa akumuliral na različne statistike.

V podatkih sem spreminjal dva dejavnika:
\begin{enumerate}
\item
Slučajno napako - spremenljivka s 4 različnimi vrstami napak: $N(0,1)$, $N(0,100)$, $\chi^2_1$ in $\chi^2_4$
\item
Korelacija  med spremenljivkami- spremenljivka s 3 različnimi vrednostmi: r = $\{0, 0.4, 0.8\}$.
S tem sem preverajal ali korelacija vpliva na ocenjevanje bet in kako je pristop robusten na multikolinearnost spremenljivk.
\end{enumerate}

Podatke sem generiral iz multivariatne normalne porazdelitve s povprečji: $\mu = \{3, 3, 4, 1 \}$ in variančno - kovariančno matriko $\Sigma$:
$$ \Sigma = 
\begin{bmatrix}
1 & r & r & r\\
r & 1 & r & r \\
r & r & 1 & r \\
r & r & r & 1 \\
\end{bmatrix}$$

pri čemer je $r$ predstavljal spreminjajoč dejavnik - korelacija. Poleg teh podatkov se dodal še eno binarno spremenljivko, ki je bila popolnoma neodvisna od zgornjih podatkov. Generiral sem jo iz $Ber(0.5)$. Velikost vzorca je bila 100.

V okvir simuliranja podatkov sodi tudi teoretične vrednosti za $\beta$. Uporabil sem naslednje vrednosti:
$$\beta_0 = -4.5, \quad \beta_1 = 0.8, \quad  \beta_2 = 0.6, \quad  \beta_3 = 3,  \quad  \beta_4 = 0, \quad  \beta_5 = 1.4$$
Odločil sem se, da je začetna vrednost absolutno nekoliko višja. Močan efekt sem dal spremenljivkama: $X_5, X_3$, šibek efekt: $X_1, X_2$ in spremenljivki $X_4$, nisem dodelil efekta.

Na takšen način sem definiral spremenljivko $Y$, ki pa sem ji dodal še slučajno napako, ki pa je slučajni dejavnik in ga je bilo moč spreminjati na 4 različnih stopnjah. Vse skupaj sem zapakiral v funkcijo, ki je vidna spodaj:

```{r}
gen.beta.data <- function(n = 100,r=0, napaka ){
  mu <- c(3, 3, 4, 1)
  Sigma <- rbind(c(1, r, r, r),
                 c(r, 1.0, r, r),
                 c(r, r, 1.0, r),
                 c(r, r, r, 1.0))
  podatki <- mvrnorm(n = n, mu = mu, Sigma = Sigma)
  #dodam še binarno spremenljivko
  podatki <- cbind(podatki, rbinom(n, size =0:1, prob=0.5)) 
  colnames(podatki) <- paste("X", 1:(length(mu)+1), sep="")
 
  # generiramo ciljno spremenljivko ("odvisno spremenljivko")
  b0 <- -4.5
  b1 <- 0.8
  b2 <- 0.6
  b3 <- 3
  b4 <- 0
  b5 <- 1.4
  
  y <- b0 + podatki[, "X1"]*b1 + podatki[, "X2"]*b2 + 
    podatki[, "X3"]*b3 + podatki[, "X4"]*b4 + podatki[, "X5"]*b5 + napaka
  # zdruzimo podatke
  # data.frame popravi konverzijo formata
  podatki <- data.frame(cbind(podatki, y))
  return(podatki)
}
```

V frekventističnem pristopu sem uporabljal funkcijo `lm`, v Bayesovem pristopu pa sem uporabljal `bayesx` iz paketa `R2BayesX`. Za vsak scenarij sem pogledal konvergenco, če smo izbrali dovolj velik burn-in (200) in pregledali avtokorelacije. Vse to lahko najdete prilogi.
Pri vsaki kombinaciji spreminjajočih se dejavnikov sem shranil podatke o ocenjenih paramaterih bet in standardne napake ocen.


## Simulacija

```{r, eval = FALSE}
pon <- 1000
sampleSize <- 100
vrsta.napake <- c("N(0,1)", "N(0,3)", "Hi_1", "Hi_4")
korelacije <- c(0, 0.4, 0.8)
metoda <- c("Freq", "Bayes")
zasnova <- expand.grid(metoda, vrsta.napake,korelacije)
zasnova.lm <- do.call(rbind, replicate(pon, zasnova, simplify=FALSE)) %>%
  `colnames<-`(c("Metoda","Napaka", "Korelacija"))
zasnova.osnova <- do.call(rbind, replicate(pon,
                                           expand.grid(vrsta.napake,korelacije),
                                           simplify=FALSE)) %>% 
  `colnames<-`(c("Napaka",  "Korelacija"))
skupaj.df <- as.data.frame(matrix(NA, nrow = nrow(zasnova.lm), ncol = 9))
table.sd <- as.data.frame(matrix(NA, nrow = nrow(zasnova.lm), ncol = 9))

start.time <- Sys.time()
i <- 1
j <- 1
while(i <= nrow(zasnova.osnova)){
  napaka.i <- as.character(zasnova.osnova[i, "Napaka"])
  if(napaka.i == "N(0,1)"){
    error <- rnorm(sampleSize, 0, 1)
  }
  else if(napaka.i == "N(0,3)"){
    error <- rnorm(sampleSize, 0, 3)
  }
  else if(napaka.i == "Hi_1"){
    error <- rchisq(sampleSize, df = 1)
  }
  else if(napaka.i == "Hi_4"){
    error <- rchisq(sampleSize, df = 4)
  }
  r.i <- zasnova.osnova[i, "Korelacija"]
  #Generiramo podakte
  data.i <- gen.beta.data(n = sampleSize, r= r.i, napaka = error)
  #FREKVENTISTIČNI PRISTOP####
  lm.model <- lm(y~., data = data.i)
  bete.hat <- summary(lm.model)$coef[,1]
  sd.bet <- summary(lm.model)$coef[,2]
  #BAYESOV PRISTOP#####
  bayesx.norm <- bayesx(y ~ X1+X2+X3+X4+X5 , data = data.i, 
                        family = "gaussian", method = "MCMC")
  bayesx.mu <- attr(bayesx.norm$fixed.effects, "sample") #za vsako beto posebaj
  bayes.mu.mean.bet <- apply(bayesx.mu, 2, mean)
  bayes.mu.sd.bet <- apply(bayesx.mu, 2, sd)
  ###SHRANIMO REZULTATE#####
  index.i <- which(zasnova.lm$Napaka == napaka.i & 
                     zasnova.lm$Korelacija==r.i& zasnova.lm$Metoda == "Freq")
  index.i.bay <- which(zasnova.lm$Napaka == napaka.i &
                         zasnova.lm$Korelacija==r.i& zasnova.lm$Metoda == "Bayes")
  skupaj.df[j, ] <- cbind(zasnova.lm[index.i.bay, ], 
                          "Beta0" = bayes.mu.mean.bet[1], 
                          "Beta1" = bayes.mu.mean.bet[2], 
                          "Beta2" = bayes.mu.mean.bet[3], 
                          "Beta3" = bayes.mu.mean.bet[4], 
                          "Beta4" = bayes.mu.mean.bet[5], 
                          "Beta5" = bayes.mu.mean.bet[6])
  table.sd[j, ] <- cbind(zasnova.lm[index.i.bay, ], 
                        "Beta0" = bayes.mu.sd.bet[1], 
                        "Beta1" = bayes.mu.sd.bet[2], 
                        "Beta2" = bayes.mu.sd.bet[3], 
                        "Beta3" = bayes.mu.sd.bet[4], 
                        "Beta4" = bayes.mu.sd.bet[5], 
                        "Beta5" = bayes.mu.sd.bet[6])
  skupaj.df[(j+1), ] <- cbind(zasnova.lm[index.i, ], 
                          "Beta0" = bete.hat[1], 
                          "Beta1" = bete.hat[2], 
                          "Beta2" = bete.hat[3], 
                          "Beta3" = bete.hat[4], 
                          "Beta4" = bete.hat[5], 
                          "Beta5" = bete.hat[6])
  table.sd[(j+1), ] <- cbind(zasnova.lm[index.i, ], 
                             "Beta0" = sd.bet[1], 
                             "Beta1" = sd.bet[2], 
                             "Beta2" = sd.bet[3], 
                             "Beta3" = sd.bet[4], 
                             "Beta4" = sd.bet[5], 
                             "Beta5" = sd.bet[6])
  j <- j + 2
  i <- i + 1
}
```
\pagebreak

## Rezultati

### Pristranskost

```{r, warning=FALSE}
#Podatki
bete.mean.est <- readRDS("data/simulation_I_bete_mean.RDS")
bete.sd.est <-readRDS("data/simulation_I_bete_sd.RDS")

original.beta <- list("Beta0" = -4.5, "Beta1"= 0.8 ,"Beta2" = 0.6,
                      "Beta3" = 3, "Beta4" = 0, "Beta5" = 1.4)

grupiraj.podatke <- bete.mean.est %>% 
  group_by(Korelacija, Metoda, Napaka) %>%
  summarise_all(mean)

#Pristranskost
bias.data <- grupiraj.podatke %>% 
  mutate_each(funs(. - original.beta$.), starts_with("Beta")) %>%
  gather(key = "Bete", "Vrednost", -c(Korelacija, Metoda, Napaka))
```

```{r Graf1, echo = FALSE, fig.width=13, fig.height=6}
ggplot(bias.data) + 
  geom_bar( aes(x = Bete, y = Vrednost, 
                color = Metoda, fill = Metoda ), 
            position = "dodge2", stat = "identity")+
  facet_grid(cols = vars(Napaka), rows = 
               vars(Korelacija))+
  ggtitle("Pristranskost ocenjenih parametrov", 
          subtitle = "Stevilo simulacij: 1000")
```

Pri standardno normalni napaki lahko vidimo, da je obe metode zelo dobro opravita nalogo in pristranskosti ni videti. Prav tako, pa tudi povečanje korelacije ne vpliva na pristranskost obeh metod. Tudi ko napaki povečamo standardni odklon na 3, se ne spremeni nič. (V eni od simulacij sem poskusil tudi standardni odklon povečati na 100 in videl, da metodi nista tako stabilni).

Pri napakah generiranih s $\chi_2$ vidimo, da s povečevanjem parametra povečujemo pristranskost začetne vrednosti - s povečevanjem parametra precenjujemo $\beta_0$. Pravtako, pa korelacija ne vpliva na pristranskost metod.

Ko primerjamo obe metodi ocenjevanja parameterov dobimo zanimive in vsaj malo zaskrbljujoče podatke. Metodi sta si v vseh scenarijih praktično enako dobri. Manjša odstopanja so pri napaki N(0,100). V poročilu je nisem izbral, ker sem imel sum, da gre za preveliko napako,saj imamo povprečja med 1-10, z standardnim odklonom 100 pa je lahko dobimo zelo naključne rezultate.

### Stanardna napaka

```{r}
grupiraj.podatke.sd <- bete.mean.est %>% 
  group_by(Korelacija, Metoda, Napaka) %>%
  summarise_all(sd) %>%  
  gather(key = "Bete", "SE", -c(Korelacija, Metoda, Napaka))

grupiraj.podatke.mean <- bete.mean.est %>% 
  group_by(Korelacija, Metoda, Napaka) %>%
  summarise_all(mean)%>%  
  gather(key = "Bete", "Mean", -c(Korelacija, Metoda, Napaka))

podatki.se.mean.join <- grupiraj.podatke.mean %>% left_join(grupiraj.podatke.sd,by = c("Korelacija", "Metoda", "Napaka", "Bete"))
```

```{r Graf2, echo = FALSE, fig.width=13, fig.height=6}
ggplot(data = podatki.se.mean.join) +
  geom_point(aes(x = Bete, y = Mean, color = Metoda ),
             position = position_dodge(width = 0.3),
             stat = "identity")+
  geom_errorbar(aes(x = Bete, 
                    ymin= Mean-1.96*SE, 
                    ymax = Mean+ 1.96*SE,
                    color = Metoda), 
                position = position_dodge(width = 0.3), 
                width = 0.3)+
  facet_grid(cols = vars(Napaka), 
             rows = vars(Korelacija))+
  labs(y= "Vrednost", x = "Bete")+
  ggtitle("Intervali zaupanja ocenjenih parametrov", 
          subtitle = "Stevilo simulacij: 1000")

```

Standardne napake narejene na simulacije sem se odločil predstaviti v obliki intervalov zaupanja po normalni porazdelitve, saj sem predpostavil, da velja centralno limitni izrek. Na grafu so tako $95 \%$ intrvali zaupanja za povprečne vrednosti koeficientov $\beta$ pri različni tipih slučajnih napak (stolpci) in korelaciji spremenljivk v podatkih (vrstice). 

V prvem scenariju - slučajna napaka N(0,1), je opaziti, da so intervali izredno majhni pri vseh 4 povezanih spremenljivkah. Pri spremenljivki $X_5$ (dihotomna spremenljivka) je standardna napaka nekoliko večja kot pri ostalih. Največja standardna napaka je pri začetnem koeficientu $\beta_0$. S povečevanje korelacij oz. kolinearnosti med spremenljivkami $X_1$ do $X_4$ vidimo, da se intervali zaupanja nekoliko širšijo. Glede na razlike v prstopih razlik ni moč opaziti.
S povečanjem standadnega odklona slučajne napaka, se intevali zaupanja nekoliko razširijo v primerjavi s scenarijem 1. Še bolj pa k temu pripomore povečanje korelacijskega koeficienta. Standardna napaka je pri $\beta_0$ največja.

V drugem delu grafa imamo 2 scenarija $\chi^2$ porazdelitve. Pri prvem imamo 1 stopnjo prostosti in se standardne napake obnašajo podobno kot pri slučajni napaki N(0,1). S povečanjem korelacij se povečuje tudi standardna napaka. Korelacijski koeficient ne vpliva na $\beta_5$, kar je pravilno. Pri 4 stopinjah prostosti pa so sicer standardne napake pri ostalih $\beta$ majhne, vendar pri $\beta_0$ teoretična vrednost na zadane intervala zaupanja. Metodi (Bayes in Frekventistčni pristop) imata premajhne razlike, da bi bile opazne.

### Koren srednje vrednosti

```{r}
mean.square.error <- function(beta.original, beta.est){
  return(sum((beta.original - beta.est)^2) / length(beta.est))
}
bete.srednje <- bete.mean.est %>% group_by(Korelacija, Metoda, Napaka)%>% 
  summarise(Beta0 = sqrt(mean.square.error(original.beta[[1]], Beta0)),
            Beta1 = sqrt(mean.square.error(original.beta[[2]], Beta1)),
            Beta2 = sqrt(mean.square.error(original.beta[[3]], Beta2)),
            Beta3 = sqrt(mean.square.error(original.beta[[4]], Beta3)),
            Beta4 = sqrt(mean.square.error(original.beta[[5]], Beta4)),
            Beta5 = sqrt(mean.square.error(original.beta[[6]], Beta5))) %>%
  gather(key = "Bete", "SrednjeVrednosti", -c(Korelacija, Metoda, Napaka))

```

```{r Graf3, echo = FALSE, fig.width=13, fig.height=6}
ggplot(data = bete.srednje) +
  geom_point(aes(x = Bete, y = SrednjeVrednosti, 
                 color = Metoda ), 
             position = position_dodge(width = 0.3),
             stat = "identity")+
  facet_grid(cols = vars(Napaka), 
             rows = vars(Korelacija))+
  labs(y = "Koren srednje kvadaratne napake")+
  ggtitle("Koren srednje kvadaratne napake ocenjenih parametrov",
          subtitle = "Stevilo simulacij: 1000")
```

Koren srednje kvadratne napake sem izračunal na naslednji način:

$$SMSE_{\beta_i} = \sqrt{\sum_{j=1}^{1000}(\hat{\beta_{ij}} - \beta_i)^2} $$
Tako sem za vsak koefeicient ter vsako kombinacijo simulacije izračunal SMSE in dobil zgornji graf. Glavna opazka je, da razlik v pristopih ni in da je največja SMSE pri parametru $beta_0$, ta je še posebno visok pri scenariju z napako $\chi^2_4$. Korelacija ne vpliva na napako SMSE. Pri scenariju z normalno slučajno se pozna vpliv povečanega standardnega odklona, kar se vidi na povečanjiu SMSE pri vseh parameterih. Vpliv neodvisne spremenljivke $X_5$ - dihotomna spremenljivka, je viden v odskoku vrednosti od ostalih pri scenariju N(0,3).


### Povprečje ocenjenih standardnih napak koeficientov

```{r}
grupiraj.podatke.sd <- bete.sd.est %>% group_by(Korelacija, Metoda, Napaka)%>% 
  summarise_all(mean) %>% 
  gather(key = "Bete", "Vrednost", -c(Korelacija, Metoda, Napaka))
```

```{r Graf4, echo = FALSE, fig.width=13, fig.height=6}
ggplot(data = grupiraj.podatke.sd) +
  geom_point(aes(x = Bete, y = Vrednost, color = Metoda ), 
             position = position_dodge(width = 0.3), 
             stat = "identity")+
  facet_grid(cols = vars(Napaka), rows = vars(Korelacija))+
  scale_x_discrete(labels = c("Beta0" , "Beta1" ,"Beta2" ,
                              "Beta3" , "Beta4", "Beta5"))+
  ggtitle("Povprecja standardne napake parametrov", 
          subtitle = "Stevilo simulacij: 1000")
```

Pričakovano podobno se obanašajo tudi povprelja standardnih napak ocenjenih $\beta$. Pri začetni vrednosti je povprečje standardne napake največeje in se spreminja z obliko slučajne napake. Pri scenariju N(0,3) se vidi nekolikošna razlika med pristopoma, saj ima Bayesov pristop nekoliko večjo povprečno standardno napako. Pri ostalih scenarijih tega iz grafa ni moč zaznati.
Scenarija s $\chi^2$ porazdelitvama imata podobne zaključke kot scenarija s normalno slučajno napako z razliko, da korelacija ne vpliva na velikost poveprečij.
Ponovno se pozna efekt neodivsne dihotomne spremenljivke $X_5$, pri kateri je standardna napaka nekoliko večja kot pri ostalih spremenljivkah. Iz standardnih napak ni razvidno katera od spremenljivk naj bi imela visok ali zmeren efekt.


## Zaključki

V simulaciji sem preveril nekatere statistike (pristranskost, MSME, standardna napaka) dveh različnih pristopov (Freq in Bayes) k ocenjevanju parametrov pri linearni regersiji, pri čemer sem imel dva spreminjajoča dejavnika: korelacijo med spremenljivkami ($X_1$ do $X_4$) in različne tipe slučajne napake. Razlik med frekventistčnim in Bayesovim pristopom ni bilo zaslediti. Sam menim, da je to zaradi tega, ker nismo v Bayesovem pristopu upoštevali dodatnega podatka (prior). Različni tipi slučajnih napak so nakazali, da je to najbolj vpliva na začetno vrednost. S povečevanjem standardnega odklona slučajne napake pri normalni porazdelitvi sem ugotovil, da dokler je standardni odklon  v okolici povprečji spremenljivk, linearna regerisja vredu deluje. S povečevanje korealcij oz. kolinearnosti pa povečujemo možnost napak. Pri slučajni napaki tipa $\chi^2$ je opaziti, da korelacija ne vpliva na nobeno od statistik (pristranskost, SMSE, standardna napaka).
Omeniti še velja, da pri neodivsni spremenljivki $X_5$, ki je binarna, SMSE in povprečje standardnih napak povečuje drugače od ostalih spremenljivk, ki so povezana s korelacijskim koeficientom.

# Primerjava metod za izbor spremenljivk pri linearni regresiji

## Opis
V drugem delu seminarske naloge, bom preveril več različnih metod za izbiro spremenljivk pri linearni regresiji. Predstavil bom 3 metode (metode sem zaradi lažje razumevanja pustil v angleškem zapisu). Prva metoda je *Reversible jump MCMC* s pomočjo programske knjižnice `nimble`. V drugi metodi imenovani Bootstrapped *Augmented Backward Elimination* z pomočjo programske knjižnice `abe`, sem s podobnimi simulacijami pregledoval deleže vrnjenih izbir spremenljivk za različne tipe slučajnih napak, korelacije in metriko (AIC, BIC, p-vrednost). Kot dodatno metoodo pa sem vpeljal še Spike - Slab metodo, pri kateri sem prav tako gledeal delež izbranih spremenljivk.

Podatke sem generiral na enak način kot v prvem delu. Dodal sem še en 5 spremenljivk, s poveprečji $\mu = \{6, 17, 22, 12, 5)\}$ in enako variančno - kovariančno matriko kot v prvem delu. Efekt dodatnih spremenljivk sem dodal na 0, saj želimo dobiti bete, katere najbolj opišejo našo odvisno spremenljivko (Y). Vse spremenljivke $X$, razen binarne $X_5$ sem centriral, preden sem jo dodal v model.

$$\beta_0 = -4.5, \quad \beta_1 = 0.8, \quad  \beta_2 = 0.6, \quad  \beta_3 = 3,  \quad  \beta_4 = 0, \quad  \beta_5 = 1.4, \quad \beta_6 = \beta_7 = \beta_8 = \beta_9 = \beta_{10} = 0$$

```{r gen.data.2}

gen.beta.data.2 <- function(n = 100,r=0, napaka){
  mu <- c(3, 3, 4, 1)
  Sigma <- rbind(c(1, r, r, r),
                 c(r, 1.0, r, r),
                 c(r, r, 1.0, r),
                 c(r, r, r, 1.0))
  mu.brez.vpliva <- c(6, 17, 22, 12, 5)
  Sigma.brez.vpliva <- rbind(c(1, r, r, r, r),
                 c(r, 1.0, r, r, r),
                 c(r, r, 1.0, r, r),
                 c(r, r, r, 1.0, r),
                 c(r, r, r, r, 1.0))
  podatki <- mvrnorm(n = n, mu = mu, Sigma = Sigma)
  podatki <- cbind(podatki, rbinom(n, size =0:1, prob=0.5))
  podatki.brez.vpliva <-mvrnorm(n = n, mu = mu.brez.vpliva, 
                                Sigma = Sigma.brez.vpliva)
  podatki <- cbind(podatki, podatki.brez.vpliva)
  colnames(podatki) <- paste("X", 1:ncol(podatki), sep="")
   # generiramo ciljno spremenljivko ("odvisno spremenljivko")
  b0 <- -4.5
  b1 <- 0.8
  b2 <- 0.6
  b3 <- 1.0
  b4 <- 0
  b5 <- 1.4
  b6 <- 0
  b7 <-0
  b8 <- 0
  b9 <-0
  b10 <- 0
  y <- b0 + podatki[, "X1"]*b1 + podatki[, "X2"]*b2 + 
    podatki[, "X3"]*b3 + podatki[, "X4"]*b4 + podatki[, "X5"]*b5 + 
    podatki[, "X6"]*b6 + podatki[, "X7"]*b7 + podatki[, "X8"]*b8 + 
    podatki[, "X9"]*b9 + podatki[, "X10"]*b10 + napaka
  podatki <- data.frame(cbind(podatki,"Y"= y))
  return(podatki)
}
```

## Reversible jump MCMC - NIMBLE

```{r nimbleFun, message=FALSE}
grafGG <- function(model, naslov = ""){
  shrani.rez <- as.data.frame(round(samplesSummary(model),2))
  shrani.rez$ime <- rownames(shrani.rez)
  z.izbrani <- shrani.rez %>% 
    filter(grepl("z",ime)) %>% 
    dplyr::select(Mean) %>% 
    mutate(X = paste("X",1:10, sep =""))
  z.izbrani$X <- factor(z.izbrani$X, levels = paste("X", 1:10, sep = ""))
  gg <- ggplot(z.izbrani, aes(x = X, y = Mean)) + geom_bar(stat = "identity")+
    ggtitle(paste("Izbira spremenljivk pri", naslov))
  return(gg)
}

get.rjMCMC <- function(selectX, Y, p=10){
  codeSelect <- nimbleCode({
      sigma ~ dunif(0, 20)
      psi ~ dunif(0,1)
      beta0 ~ dnorm(0, sd=100)
      for(i in 1:p) {
        z[i] ~ dbern(psi) #indikator za vsak koeficient
        beta[i] ~ dnorm(0, sd = 100)
        zbeta[i] <- z[i] * beta[i]
      }
      for(i in 1:N) {
        y[i] ~ dnorm(beta0 + inprod(X[i, 1:p], zbeta[1:p]), sd = sigma)
      }
    })
    
    N <- dim(selectX)[1]
    p <- dim(selectX)[2]
    constantsSelect <- list(N = N, p = p)
    initsSelect <- list(sigma = 1, psi = 0.5, beta0 = 0,
                        beta = rnorm(p),
                        z = sample(c(0, 1), p, replace = TRUE))
    dataSelect <- list(y = Y, X = selectX)
    RmodelRJ <- nimbleModel(code = codeSelect, constants = constantsSelect, #isto
                            inits = initsSelect, data = dataSelect)
    confRJ <- configureMCMC(RmodelRJ) #isto
    confRJ$addMonitors('z') #isto
    configureRJ(confRJ,
                targetNodes = 'beta',
                indicatorNodes = 'z',
                control = list(mean = 0, scale = .2))
    RmcmcRJ <- buildMCMC(confRJ)
    CmodelRJ <- compileNimble(RmodelRJ)
    CmcmcRJ <- compileNimble(RmcmcRJ, project = CmodelRJ)
    samplesRJ <- runMCMC(CmcmcRJ, niter = 12000, nburnin = 2000)
    return(samplesRJ)}
```
\pagebreak

### Rezultati

Za vsak scenarij bom pregledal konvergenco in posteriorno porazdelitev in pogledal katere spremenljivke bi dodali v model. Konvergenco in posteriorno porazdelitev sem narisal na dveh grafih - tisti, ki imajo ničelni koeficient in tiste, ki imajo neničelne koeficiente na drug graf.

#### Slučajna napaka: N(0,1)

```{r, message=FALSE}

data.NIBLE.N1 <- gen.beta.data.2(100, napaka = rnorm(100))
data.NIBLE.N1.selectY <- data.NIBLE.N1$Y
data.NIBLE.N1.selectX <- sweep(data.NIBLE.N1[,-5], 2, colMeans(data.NIBLE.N1[,-5]), FUN="-")[,-10] #centriramo
data.NIBLE.N1.selectX$X5 <- data.NIBLE.N1$X5
data.NIBLE.N1.selectX <- data.NIBLE.N1.selectX[, c(1,2,3,4,10,5,6,7,8,9)]
mod.N1 <- get.rjMCMC(data.NIBLE.N1.selectX, data.NIBLE.N1.selectY)
```

![Konvergenca in posteriorne porazdelitve za neničelne bete](img/N1_neBeta.png)

![Konvergenca in posteriorne porazdelitve za ničelne bete](img/N1_Beta.png)

Konvergence so v skladu z pričakovanji in glede na grafičen prikaz za vse parametre model skonvergira. Posteriorne porazdelitve so pri neničelnih betah pravilno porazdelje s povprečji, ki se skladajo s teoretičnimi vrednostmi.

```{r Graf5a, echo = FALSE, fig.width=13, fig.height=6}
grafGG(mod.N1, "modelu z nakljucno napako: N(0,1)")
```
Model pravilno izbere vse 4 spremenljivke z zelo visokim deležem verjetja. Tudi ko sem poskusil s povečanjem korealacij, ga to ni zmotilo in se grafa nista razlikovala. 

#### Slučajna napaka: N(0,3)

```{r, message=FALSE}
data.NIBLE.N3 <- gen.beta.data.2(100, napaka = rnorm(100))
data.NIBLE.N3.selectY <- data.NIBLE.N3$Y
data.NIBLE.N3.selectX <- sweep(data.NIBLE.N3[,-5], 2, colMeans(data.NIBLE.N3[,-5]), FUN="-")[,-10] #centriramo
data.NIBLE.N3.selectX$X5 <- data.NIBLE.N3$X5
data.NIBLE.N3.selectX <- data.NIBLE.N3.selectX[, c(1,2,3,4,10,5,6,7,8,9)]
mod.N3 <- get.rjMCMC(data.NIBLE.N3.selectX, data.NIBLE.N3.selectY)
```
![Konvergenca in posteriorne porazdelitve za neničelne bete](img/N3_neBeta.png)

![Konvergenca in posteriorne porazdelitve za ničelne bete](img/N3_Beta.png)
Konvergence so za ničelne v skladu z pričakovanji, kot tudi posteriorne porazdelitve z zelo visokim verjetjem okoli 0. Težav s konvergenco ni zaslediti tudi pri neničelnih parametrih $\beta$.

```{r Graf5b, echo = FALSE, fig.width=13, fig.height=6}
grafGG(mod.N3, "modelu z nakljucno napako: N(0,3)")
```
S povečanjem standardnega odklona slučajne napake se pri izboru spremenljivk ni spremenilo. Izbrane spremenljivke so bile še vedno izbrane pravilno in z visoko vrednostjo verjetja. 

#### Slučajna napaka: $\chi^2_1$

```{r, message=FALSE}
data.NIBLE.H1 <- gen.beta.data.2(100, napaka = rchisq(100, 1))
data.NIBLE.H1.selectY <- data.NIBLE.H1$Y
data.NIBLE.H1.selectX <- sweep(data.NIBLE.H1[,-5], 2, 
                               colMeans(data.NIBLE.H1[,-5]), 
                               FUN="-")[,-10] #centriramo
data.NIBLE.H1.selectX$X5 <- data.NIBLE.H1$X5
data.NIBLE.H1.selectX <- data.NIBLE.H1.selectX[, c(1,2,3,4,10,5,6,7,8,9)]
mod.H1 <- get.rjMCMC(data.NIBLE.H1.selectX, data.NIBLE.H1.selectY)

```
![Konvergenca in posteriorne porazdelitve za neničelne bete](img/H1_neBeta.png)

![Konvergenca in posteriorne porazdelitve za ničelne bete](img/H1_Beta.png)

```{r Graf5c, echo = FALSE, fig.width=13, fig.height=6}
grafGG(mod.H1, "modelu z nakljucno napako: Hi_1")
```
Ko spremenimo porazdelitev na $\chi_1^2$ vidimo, da model ni več tako stabilen. Konvergenca je sploh pri spremenljivki $X_6$ zelo problematična, prav tako pa tudi pri ničenih parametrih spremenljivke $X_3$. To se pozna tudi na izbiri spremenljivk, ki je zato nepravilna in zelo netočna. Model namreč izbere samo spremenljivko $X_3$, ki pa ima že prej omenjeno težavo s konvergenco. 

#### Slučajna napaka: $\chi^2_4$

```{r, message=FALSE}
data.NIBLE.H4 <- gen.beta.data.2(100, napaka = rchisq(100, 4))
data.NIBLE.H4.selectY <- data.NIBLE.H4$Y
data.NIBLE.H4.selectX <- sweep(data.NIBLE.H4[,-5], 2, 
                               colMeans(data.NIBLE.H4[,-5]), 
                               FUN="-")[,-10] #centriramo
data.NIBLE.H4.selectX$X5 <- data.NIBLE.H4$X5
data.NIBLE.H4.selectX <- data.NIBLE.H4.selectX[, c(1,2,3,4,10,5,6,7,8,9)]
mod.H4 <- get.rjMCMC(data.NIBLE.H4.selectX, data.NIBLE.H4.selectY)
```
![Konvergenca in posteriorne porazdelitve za neničelne bete](img/H4_neBeta.png)

![Konvergenca in posteriorne porazdelitve za ničelne bete](img/H4_Beta.png)

```{r Graf5d, echo = FALSE, fig.width=13, fig.height=6}
grafGG(mod.H4, "modelu z nakljucno napako: Hi_4")
```
Podobna zgodba kot že pri prejšnem primeru, le da je za otenek večja verjetnost pri spremenljivki $X_1$, kar pa ne popravi kakovosti izbire modela. Pri tem modelu je problematična konvergenca spremenljivke $X_9$. Model slabo izbere spremenljivke.

### Zaključek

Pri metodi Reverse Jump MCMC s programsko knjižnico `nimble`, je bilo moč opaziti, da pri slučajni napaki, ki obsega normalno porazdelitev, model dobro napoveduje izbiro spremenljivk. S tem ko pa spremenimo vrsto porazdelitve slučajne napake, pa metoda ni tako robustna. Razlog zato vidim v tem, saj smo izbrali veliko število hiperparametrov s normalno porazdelitvijo, kar daje prednost slučajnim napakam s normalno porazdelitivijo. Iz tega tudi izhaja, da pri slučajni napaki $\chi_1^2$ dobimo povsem slabo ocenjen model, s vprašljivo konvergenco.

## Bootstrapped Augmented Backward Elimination - ABE

Za potrebe simulacije sem naredil funkcijo, ki je vrnila model `abe`, 
imela pa je naslednje vhodne podatke: spremenljivke X, Y, metriko s katero smo določali,
kateri model je najboljši, število bootstrap ponovitev.

```{r}
selection.ABE <- function(dataSetSelectX, Y, p = 10, metrika = "AIC", alpha=0.2, num.boot =500){
  data.Skupaj <- cbind(dataSetSelectX, "Y" = Y)
  fit <- lm(Y ~ . , data = data.Skupaj, x = TRUE, y = TRUE)
  if(metrika %in% c("AIC", "BIC")){
    abe.fit.boot <- abe.boot(fit, criterion = metrika, data = dataSetSelectX, 
                             tau = Inf, exp.beta = FALSE, num.boot = num.boot,
                             type.boot = "bootstrap")
  }
  else{
    abe.fit.boot <- abe.boot(fit, criterion = metrika, alpha = alpha, 
                             data = dataSetSelectX, tau = Inf, exp.beta = FALSE,
                             num.boot = num.boot, type.boot = "bootstrap")
  }
  return(abe.fit.boot)
}
```

### Opis simulacije

Za simulacije sem se odločil, saj me je zanimalo odstopanje različnih metod, glede na korelacijo in vrsto slučajne napake. Zato sem se odločil, da za vse 3 metrike naredim 100 ponovitev vseh kombinacij korelacije ( r = 0, 0.8) in vrste napak (enake kot v prvem delu).

```{r,eval = FALSE}
pon <- 100
sampleSize <- 100
vrsta.napake <- c("N(0,1)", "N(0,3)", "Hi_1", "Hi_4")
#vrsta.metode <- c("AIC", "BIC", "alpha")
korelacije <- c(0, 0.8)
zasnova <- expand.grid(korelacije, vrsta.napake)
zasnova <- do.call(rbind, replicate(pon, zasnova, simplify=FALSE)) %>%
  `colnames<-`(c("Korelacija","Napaka"))
matrika.rez <- matrix(NA, nrow = 3*nrow(zasnova), ncol = 14)

i = 1
j = 1
while(i < nrow(zasnova)){
  vrsta.napake.i <- zasnova[i, "Napaka"]
    if(vrsta.napake.i == "N(0,1)"){
      error <- rnorm(sampleSize, 0, 1)
    }
    else if(vrsta.napake.i == "N(0,3)"){
      error <- rnorm(sampleSize, 0, 3)
    }
    else if(vrsta.napake.i == "Hi_1"){
      error <- rchisq(sampleSize, df = 1)
    }
    else if(vrsta.napake.i == "Hi_4"){
      error <- rchisq(sampleSize, df = 4)
    }
    r.i <- zasnova[i, "Korelacija"]
    
  data.ABE <- gen.beta.data.2(sampleSize, r = r.i, napaka = error)
  data.ABE.selectY <- data.ABE$Y
  data.ABE.selectX <- sweep(data.ABE[,-5], 2, colMeans(data.ABE[,-5]), FUN="-")[,-10] #centriramo
  data.ABE.selectX$X5 <- data.ABE$X5
  data.ABE.selectX <- data.ABE.selectX[, c(1,2,3,4,10,5,6,7,8,9)]
  abe.AIC <-selection.ABE(data.ABE.selectX, Y =data.ABE.selectY, 
                             p = 10, metrika = "AIC",num.boot = 500)
  abe.BIC <-selection.ABE(data.ABE.selectX, Y =data.ABE.selectY, 
                          p = 10, metrika = "BIC",num.boot = 500)
  abe.alpha <-selection.ABE(data.ABE.selectX, Y =data.ABE.selectY, 
                          p = 10, metrika = "alpha",num.boot = 500)
  
  rez.aic <- summary(abe.AIC)$var.rel.frequencies
  rez.bic <- summary(abe.BIC)$var.rel.frequencies
  rez.alpha <- summary(abe.alpha)$var.rel.frequencies
  matrika.rez[j,] <- c("R" = r.i,  "Metoda" = 1, "Napaka" = vrsta.napake.i, rez.aic)
  matrika.rez[j+1,] <- c("R" = r.i,  "Metoda" = 2, "Napaka" = vrsta.napake.i, rez.bic)
  matrika.rez[j+2,] <- c("R" = r.i,  "Metoda" = 3, "Napaka" = vrsta.napake.i, rez.alpha)
  j <- j + 3 
  i <- i + 1
}

rez.df <- na.omit(as.data.frame(matrika.rez))
rez.df.nov <- as.data.frame(apply(rez.df, 2, as.numeric))
rez.df.nov$Metoda <- factor(rez.df.nov$V2, labels = c("AIC", "BIC", "alpha"))
rez.df.nov$Napaka <- factor(rez.df.nov$V3,labels = vrsta.napake)
rez.df.nov$Korelacija <- rez.df.nov$V1
abe.rez <- rez.df.nov[,4:17]
colnames(abe.rez) <- c( paste("X", 0:10, sep=""),"Metoda", "Napaka","Korelacija")
```

### Rezultati


```{r}
abe.data <- readRDS("data/abe_simulation.RDS")

aba.data.sim <- abe.data %>%
  group_by(Korelacija, Metoda, Napaka)%>%
  summarise_all(mean) %>% 
  gather(key = "X", "Vrednost", -c(Korelacija, Metoda, Napaka))  %>%
  filter(X != "X0")

aba.data.sim$X <- factor(aba.data.sim$X, levels = paste("X", 1:10, sep = ""))
```
Pri predstavitvi rezultatov bom izpustil parameter $\beta_0$, ki je v prisoten v vsakem modelu.

#### AIC
```{r Graf6, echo = FALSE, fig.width=13, fig.height=6}
ggplot(aba.data.sim %>% filter(Metoda == "AIC")) + 
  geom_point( aes(x = X, 
                y = Vrednost*100 ), 
            position = position_dodge2(width = 0.3), 
            stat = "identity")+
  facet_grid(cols = vars(Napaka), 
             rows = vars(Korelacija), 
             scales = "free_x", 
             drop = TRUE)+
  scale_y_continuous(breaks = seq(0,25,2))+
  ggtitle("Relativna frekvenca izbire pri metriki AIC", 
          subtitle = "Stevilo simulacij: 100")+
    labs(x = "X", "Delež [%]")
```
Kot vidimo, so razlike v deležih spremenljivk zelo majhne. Sklepam, da je to posledica boostrapa 500, saj za vsako kombinacijo in vsako metriko naredimo 100 ponovitev po 500 bootstrap vzorcev, kar daje enakomerno porazdelitev vsem spremenljivkam (ali pa je samo slab model). Omeniti še velja, da se pri povečanju korelacije deleži vključevanja v model povečujejo in spremenljivka $X_5$ se začne vesti drugače - porast vključevanja v model bistveno pade.
Zaradi zelo majhnih razlik si poglejmo posebaj primer N(0,1) in r = 0.

```{r Graf6a, echo = FALSE, fig.width=13, fig.height=6}
ggplot(aba.data.sim %>% filter(Metoda == "AIC" & Korelacija == 0 & Napaka == "N(0,1)"))+
  geom_bar( aes(x = reorder(X, -Vrednost), 
                y = Vrednost*100, 
                color = Metoda, 
                fill = Metoda ), 
            stat = "identity")+
  scale_y_continuous(breaks = seq(0,25,2))+
  ggtitle("Relativna frekvenca izbire pri metriki AIC", 
          subtitle = "N(0,1) in r=0") +
  labs(x = "X", "Delez [%]")
```
Ko pogledamo deleže, vidimo, da imata najvišji deleže spremenljivke, ki imajo $\beta = 0$, kar nakazuje, da v tem našem primeru model ne bi pravilno izbiral. Med najvišjimi deleži je kar 5 spremenljivk, ki imajo $\beta$ fiksirano na 0. Podobno je tudi pri drugih scenarijih.


#### BIC
```{r Graf7, echo = FALSE, fig.width=13, fig.height=6}
ggplot(aba.data.sim %>% filter(Metoda == "BIC")) + 
  geom_point(aes(x = X,
                 y = Vrednost*100),
             position = position_dodge2(width = 0.3),
             stat = "identity")+
  facet_grid(cols = vars(Napaka), 
             rows = vars(Korelacija),
             scales = "free_x", 
             drop = TRUE)+
  ggtitle("Relativna frekvenca izbire pri metriki BIC", 
          subtitle = "Stevilo simulacij: 100")+
  labs(x = "X", "Delež [%]")
```
Tako kot pri metriki AIC, so tudi pri BIC razlike v deležih zelo majhne. Razlika, ki jo je moč opaziti je, da imajo spremenljivke $X_6$ do $X_10$ nekoliko manjše deleže pri normalni slučajni napaki in korelaciji r = 0. Pri slučajnih napak iz porazdelitve $\chi^2$, se stvari obnašajo čudno in nepravilno (največje deleže imajo spremenljivke s $\beta = 0$).
S tem ko povečamo korelacijo med spremenljivkami se nam zgodi, da binarna spremenljivka ne opisje več dobro modela, zato je njen delež daleč najslabši. 
Še posebno pri slučajni napaki N(0,3) in r = 0 so spremenljivke pravilno selekcionirane, ampak ko povečamo korelacijo, selekcija ni več pravilna, zato ugotavljam, da je korelacija oz. kolinearnost eden od močnih vplivov na izbiro spremenljivk. Vseeno si poglejmo od bližje rezulatate pri slučajni napaki N(0,3) in r = 0.

```{r Graf7a, echo = FALSE, fig.width=13, fig.height=6}
ggplot(aba.data.sim %>% filter(Metoda == "BIC"& Korelacija == 0 & Napaka == "N(0,3)"))+
  geom_bar(aes(x = reorder(X, -Vrednost),
                 y = Vrednost*100),
             position = position_dodge2(width = 0.3),
             stat = "identity")+
  facet_grid(cols = vars(Napaka), 
             rows = vars(Korelacija),
             scales = "free_x", 
             drop = TRUE)+
  labs(x = "X", y = "Delez [%]")+
  ggtitle("Relativna frekvenca izbire pri metriki BIC", 
          subtitle = "N(0,3) in r=0")
```
Kot vidimo je vrstni red pravilen, le da gre pri $X_7$ in $X_5$ za minimalne razlike.


#### p-vrednost

```{r Graf8, echo = FALSE, fig.width=13, fig.height=6}
ggplot(aba.data.sim %>% filter(Metoda == "alpha")) + 
  geom_point(aes(x = X,
                 y = Vrednost*100),
             stat = "identity")+
  facet_grid(cols = vars(Napaka), 
             rows = vars(Korelacija),
             scales = "free_x", 
             drop = TRUE)+
  ggtitle("Relativna frekvenca izbire pri metriki p-vrednost", 
          subtitle = "Stevilo simulacij: 100")+
  labs(x = "X", "Delež [%]")
```
Pri metriki p-vrednosti sem alpha fiksiral na 0.2, dobimo zanimive rezultate. Pri scenarijih z slučajno napako iz normalne porazdelitve so selekcije spremenljivk boljše pri večjem standardne odklonu, pri  korealcijskih koeficientu r = 0. Ko povečamo korealcijski koefiecient se delež pravilno napovedanih spremenljivk znatno zmanjša. Pri scenarijih iz $\chi^2$ porazdelitve, da spremenljivke z največjim deležem izbire imajo teoroetičen koeficien enak 0.
S povečanjem korealcij se ponovno opazi razliko na spremenljivki $X_5$. 
Tokrat si podrobneje oglejmo $\chi^2_1$ pri korelaciji r = 0.


```{r Graf8a, echo = FALSE, fig.width=13, fig.height=6}
ggplot(aba.data.sim %>% filter(Metoda == "alpha"&
                                 Korelacija == 0 & 
                                 Napaka =="Hi_1"))+
  geom_bar(aes(x = reorder(X, -Vrednost),
                 y = Vrednost*100),
             stat = "identity")+
  labs(x = "X", y = "Delez [%]")+
  ggtitle("Relativna frekvenca izbire pri metriki BIC", 
          subtitle = "Hi_1 in r = 0")+
  labs(x = "X", "Delež [%]")
```
Dejstvo je, da so razlike tako majhne, da se delež največkrat izbrane spremenljivke v primerjavi z najmanjšim deležem izbrane spremenljivke razlikuje za 0.06. Težko rečemo, da bi v tem primeru izbrali pravilne spremenljivke.

### Zaključek

Ko pogledamo vse tri različne metrike, lahko rečemo, da so razlike pri nekaterih metrikah tako majhne, da  se nam hitro lahko zgodi da vzmemo nevplivno spremenljivko. Simulacija je vseeno pokazala, da je BIC metrika, dajala najbolj zanesljive rezultate. Rezultati so bili dokaj natančni samo za slučajno napako normalne porazdelitve, pri hi-kvadrat porazdelitvi, so bile pravilne spremenljivke redkeje izbrane. Korelacija je pomemnbno vplivala na izbor spremenljvik, tako, da v tem primeru priororčam izbor glede na metriko p-vrednosti.

## Spike and Slab - BoomSpikeSlab

Spike and Slab regresija se Bayesovi statistiki uporablja predvsem za selekcijo spremenljivk, ko imamo več spremenljivk kot statisitčnih enot. Bralec si lahko več prebere [**tukaj**](http://www.batisengul.co.uk/post/spike-and-slab-bayesian-linear-regression-with-variable-selection/) ali [**tukaj**](https://arxiv.org/pdf/math/0505633.pdf)

### Predstavitev simulacije

```{r}
selection.spike.slab <- function(dataSetSelectX, Y){
  dataX <- cbind(rep(1, nrow(dataSetSelectX)),
                 as.matrix(dataSetSelectX))
  prior <- IndependentSpikeSlabPrior(dataX, Y,
                                     prior.df = .0)
  dataX <- dataX[,-1]
  model <- lm.spike(Y ~ dataX,  niter = 1000, prior = prior)
  return(model)
}

```
V enostavni simulaciji bom naredil 100 ponovitev zgoraj opisane funkcije, pri čemer me je zanimala frekvenca in izbor izbranih spremenljivk. To sem naredil za vse vse 4 vrste napak in dve različni vrednosti korelacije.


```{r SpikeSim, eval= FALSE}
pon <- 100
sampleSize <- 100
vrsta.napake <- c("N(0,1)", "N(0,3)", "Hi_1", "Hi_4")
#vrsta.metode <- c("AIC", "BIC", "alpha")
korelacije <- c(0, 0.8)
zasnova <- expand.grid(korelacije, vrsta.napake)
zasnova <- do.call(rbind, replicate(pon, zasnova, simplify=FALSE)) %>%
  `colnames<-`(c("Korelacija","Napaka"))
matrika.rez <- matrix(NA, nrow = nrow(zasnova), ncol = 13)
i = 1

while(i <= nrow(zasnova)){
  vrsta.napake.i <- zasnova[i, "Napaka"]
  if(vrsta.napake.i == "N(0,1)"){
    error <- rnorm(sampleSize, 0, 1)
  }
  else if(vrsta.napake.i == "N(0,3)"){
    error <- rnorm(sampleSize, 0, 3)
  }
  else if(vrsta.napake.i == "Hi_1"){
    error <- rchisq(sampleSize, df = 1)
  }
  else if(vrsta.napake.i == "Hi_4"){
    error <- rchisq(sampleSize, df = 4)
  }
  r.i <- zasnova[i, "Korelacija"]
  
  data.Spike <- gen.beta.data.2(sampleSize, r = r.i, napaka = error)
  data.Spike.selectY <- data.Spike$Y
  data.Spike.selectX <- sweep(data.Spike[,-5], 2, colMeans(data.Spike[,-5]), FUN="-")[,-10] #centriramo
  data.Spike.selectX$X5 <- data.Spike$X5
  data.Spike.selectX <- data.Spike.selectX[, c(1,2,3,4,10,5,6,7,8,9)]
  
  mod.spikeSlab <- selection.spike.slab(dataSetSelectX = data.Spike.selectX, Y =data.Spike.selectY)
  inc.prob <- summary(mod.spikeSlab)$coef[,"inc.prob"]
  inc.prob.urejen <- inc.prob[order(factor(names(inc.prob), levels = paste("dataXX", 0:10, sep="")))]

  matrika.rez[i,] <- c("R" = r.i,"Napaka" = vrsta.napake.i, inc.prob.urejen)
  i <- i + 1
}

spikeSlab.df <- as.data.frame(matrika.rez[,-13])
spikeSlab.df$V2 <- factor(spikeSlab.df$V2,labels = vrsta.napake)
colnames(spikeSlab.df) <- c("Korelacija", "Napaka", paste("X", 1:10, sep =""))

```


### Rezultati

```{r}
spikeSlab.data <- readRDS("data/spikeSlab_simulation.RDS")

spike.data.sim <- spikeSlab.data %>%
  group_by(Korelacija, Napaka)%>%
  summarise_all(mean) %>% 
  gather(key = "X", "Vrednost", -c(Korelacija, Napaka))
spike.data.sim$X <- factor(spike.data.sim$X, levels = paste("X", 1:10, sep = ""))
```


```{r Graf9, echo = FALSE, fig.width=13, fig.height=6}
ggplot(spike.data.sim) + 
  geom_point(aes(x = X,
                 y = Vrednost*100),
             stat = "identity")+
  facet_grid(cols = vars(Napaka), 
             rows = vars(Korelacija),
             scales = "free_x", 
             drop = TRUE)+
  labs(y = "Delez [ % ]")+
  ggtitle("Relativna frekvenca izbire spremenljivk z metodo SpikeSlab", subtitle = "Stevilo simulacij: 100")
```
Metoda SpikeSlab se je izkazala kot najbolj uspešna metoda v iskanju najboljši spremenljivk za opis spremenljvike Y. Pri korealcijskem koeficientu r = 0, namreč za vse vrste slučajnih napak pravilno napove največji delež za spremenljvke, ki imajo neničelni koeficient $\beta$. Če primerjamo po posameznih porazdelitvah vidimo, da pri normalni sluačjni napaki, večji standardni odklon nekoliko pokvari rezultate, vendar nikoli ni vkljičil modela, ki bi vseboval ničelni koeficient $\beta$. Pri hi-kvadrat porazdelitvi s eno prostostno stopnjo imajo teoretično pravilne spremenljivke visok delež izbire, s povečavanjem prostostnih stopenj na štiri, pa se ta delež nekoliko zmanjša. Metoda pravilno zazna tudi binarno spremenljivko $X_5$. S povečavo korelacijskega koeficienta (r = 0.8) se deleži nekoliko zmanjšajo, vendar to nespremeni bistveno rezultatov, razen pri  slučajni napaki - N(0,3), kjer je delež za spremenljivko $X_4$ ($\beta_4$ = 0) nekoliko večji kot $X_5$ ($\beta_5 \ne 0$).

## Zaključek

Kot najboljša metoda se mi je zdela SpikeSlab metoda, saj je delovala najbolj robustno, tudi na slučajnih napakah porazdeljene iz $\chi_2$. Na drugo mesto bi postavil Reverse jump MCMC metodo, ki je za normalne porazdelitve delovala zelo dobro, zmanjkalo jo je pri drugi vrsti porazdelitve. Pri bacward bootstrap elimination se mi zdi, da je vseeno najboljše izbira bila BIC kriterij. Možno, je da je kakšna napaka, saj so deleži preveč enakomerno porazdeljeni po spremenljvkah, tudi v primerih ko je šlo za zelo nizko slučajno napako.


# Praktična uporava Bayesove statistike

## Podatki

Podatke sem pridobil za namene Statističnega svetovanja, ki ga opravljam na Onkološkem inštitu v Ljubljani. Raziskovalca zanima varnostni pas pri obsevanju z radioterapijo. Vsak pacient je deležen svojega obsevalnega načrta, ki zajema različno število frakcij (obsevanje). Teh frakcij je lahko do 35.  Pri obsevanju se pacient postavi na mizo, kjer ga s pomočjo slik skalibirajo na teoretično pravilen položaj. Ker pa človek ni togo telo, se vseskozi premika (dihanje, napete mišice, itd.). Zato v ta namen gledajo premike v x, y in z smeri, ki so se zgodili v času ene frakcije od teoretične postavitve, ki bi jo moral pacient dosegati. Ti premiki po oseh določajo varnostni pas obsevanja, da pacientov tumor vseeno v celoti obsevan. Imenujemo jih interfrakcijski razmiki.

V prvem delu se bom osredotočil kaj vpliva na  translacijske premike po y-osi (`Lng`). Neodvisne spremenljivke, ki jih bom vključil v model sta: vrsta raka in število frakcij. Model se mi zdi smiseln, saj me zanima ali vrsta raka dejansko pomeni večje translacijske premike pri radioterapiji (pri kateri vrsti raka, se pacienti bolj premikajo) in ali število obsevanj vpliva na napako. Translacij `Vrt` in `Lat`, ter rotacije v model nisem dodajal v model, saj ne gre za neodvisne spremenljivke. Predpostavljam, da se pacient ne more premakniti samo po eni osi.

```{r, echo = FALSE}
kable(head(dt), "markdown")
```

### Vrsta raka

```{r VrstaRaka , echo = FALSE, fig.width=5, fig.height=4,fig.align="center"}
vrsta <- prop.table(table(dt$RefIso))*100
bp <- barplot(vrsta, main = "Relativna frekvenca vrste raka", 
        ylim= c(0,100))
text(bp, vrsta/2, labels = paste(round(vrsta, digits = 2), "%", sep =""))

```

V podatkovju imamo 115 pacientov, ki je skupaj opravilo 3393 obsevanj z radioterapijo. 64 \% je imelo raka v glavi, ostali pa na vratu. Obsevanje je potekalo od septembra 2012 do marca 2015.


### Število frakcij

```{r PorazdelitevFrakcij, echo = FALSE, fig.width=6, fig.height=4,fig.align="center"}
hist(povprecje.pacientov$st.frakcij, breaks = 10, probability = F, main = "Porazdelitev stevila frakcij", xlim = c(0, 35), xlab = "Stevilo frakcij", ylab = "Frekvenca")
```

Za porazdelitev števila frakcij med pacienti, ki velja za ključno v mojem problemu, je na vzorcu vidna ena velika skupina, ki obsega 84 \% pacientov, ki ima med 25 in 35 frakcij. Skoraj 10 \% pacientov ima število obsevanj med 15 in 25, medtem ko ima le 6 \% pacientov od 1 do 15 obsevanj.

### Translacije in rotacije pacientov

```{r TransRotac, echo = FALSE, fig.width=10, fig.height=7,fig.align="center"}
par(mfrow = c(2,2))
hist(dt$Vrt, breaks = 15, probability = T, main = "Porazdelitev premikov po x-osi", xlab = "Napaka", ylab = "Verjetnost")
lines(density(dt$Vrt), col = "red", lwd = 2)
hist(dt$Lng, breaks = 15, probability = T, main = "Porazdelitev premikov po y-osi", xlab = "Napaka", ylab = "Verjetnost")
lines(density(dt$Lng), col = "red", lwd = 2)
hist(dt$Lat, breaks = 15, probability = T, main = "Porazdelitev premikov po z-osi", xlab = "Napaka", ylab = "Verjetnost")
lines(density(dt$Lat), col = "red", lwd = 2)
hist(dt$Rtn, breaks = 25, probability = T, main = "Porazdelitev rotacij", xlab = "Napaka", ylab = "Verjetnost")
lines(density(dt$Rtn), col = "red", lwd = 2)
```


```{r echo=FALSE, paged.print=TRUE}

r <- round(as.data.frame(psych::describe(dt[,c("Vrt", "Lng", "Lat", "Rtn")]))[,c(2,3,4,5,8,9,11, 12)],2)
kable(r, format ="markdown")

```

Porazdelitve po oseh so normalno porazdeljene s precej podobnim povprečji. Pri porazdelitvi rotacij ne moremo trditi, da je spremenljivka normalno porazdeljena, saj je prevelik del vrednosti okoli 0, ostale vrednosti pa so minimalno prisotne v negativno in pozitivno smer.

### Frekventistični model


```{r}
lm.mod <- lm(Lng ~ Vrt + Lat + RefIso, data = podatki.st.frakcij)
summary(lm.mod)
```

```{r, echo = FALSE, fig.width=10, fig.height=7,fig.align="center"}
par(mfrow = c(2,2))
plot(lm.mod)
```

Predpostavka o konstantni varianci je izpolnjena, problematični so morda ostanki, ki ne kažejo, da so normalno porazdeljeni. Vseeno bom nadaljeval z analizo.

Pregledam še kolinearnost obeh spremenljivk in vidim, da kolinearnost ni prisotna.

```{r}
kable(vif(lm.mod), "markdown", col.names = "VIF")
```

Pregledali smo osnovne karakteristike linearnega modela, ki jih smatram, da jih moramo narediti, tudi če se odlčamo za Bayesovo statistiko.

### Bayesev model

```{r}
fit2.bayesx <- bayesx(Lng ~ Vrt+ Lat + RefIso , 
                      data = podatki.st.frakcij, 
                      family = "gaussian", method = "MCMC", iterations = 12000,
                      burnin = 2000)

b.Vrt <- attr(fit2.bayesx$fixed.effects, "sample")[,2]
b.Lat <- attr(fit2.bayesx$fixed.effects, "sample")[,3]
b.RefIso <- attr(fit2.bayesx$fixed.effects, "sample")[,4]

summary(fit2.bayesx)
```


## Konvergenca

```{r konvergencaPlot, fig.width=6, fig.height=6,fig.align="center"}
par(mfrow = c(2, 2))
plot(b.Vrt, type = "l", main = "Koeficient za stevilo frakcij, veriga",
     xlab = "")
plot(b.Lat, type = "l", main = "Koeficient za stevilo frakcij, veriga",
     xlab = "")
plot(b.RefIso, type = "l", main = "Koeficient za vrsto raka, veriga",
     xlab = "")

```

Konvergence za vse parametre je v skladu z dovoljenim. 

## Interpretacija

```{r PosteriornaPorazdPlot, fig.width=8, fig.height=5,fig.align="center"}
par(mfrow = c(2, 2))
hist(b.Vrt, prob = T, main = "Koeficient za premike v vertikalni smeri,\nrobna aposteriorna porazdelitev")
lines(density(b.Vrt), col = "red", lwd = 2)
hist(b.Lat, prob = T, main = "Koeficient za premike horizontalni smeri, \nrobna aposteriorna porazdelitev")
lines(density(b.Lat), col = "red", lwd = 2)
hist(b.RefIso, prob = T, main = "Koeficient za vrsto raka, \nrobna aposteriorna porazdelitev")
lines(density(b.RefIso), col = "red", lwd = 2)
```


Levi graf zgoraj prikazuje porazdelitev za koeficient $\beta_1$, ki določa efekt za spremenljivko `Vrt`. Povprečje porazdelitve je  -0.1372, 95 \% interval pa je med  -0.1634 in  -0.1110. Spremenljivka `Lat`, ki je skrita pod koeficient $\beta_2$ ima normalno porazdelitev s povprečjem 
-0.0895, 95 \% interval med -0.1237 in -0.0571. Spremenljivka `RefIso`, ki določajo vrsto raka. Njen pripadajoči parameter $\beta_3$ je porazdeljen normalno, s povprečjem 0.0313, njen 95 \% interval pa je med  0.0146 - 0.0479.

Ob upoštevanju `Vrt` in `Lat` v modelu je `Lng` za paciente z rakom na vratu za 0.0313 enote, kot tiste z rakom v glavi. Ob upoštevanju vrednosti z  `RefIso` in `Lat` velja: če se premik v vertikalni smeri poveča za 1 se `Lng` v povprečju zmanjša za 0.1372. Ob upoštevanju vrednosti z  `RefIso` in `Vrt` velja: če se premik v horizontalni smeri (Lat) poveča za 1 se `Lng` v povprečju zmanjša za 0.0895.



## Hierarhični model

Hierarhičen model sem definiral na naslednji način. Zanimala me bo spremenljivka `Lng`, glede na paciente, in kako se razlikuje med njimi. Pri tem bom naredil pogumno predpostavko o tem, da je varianca med posameznimi pacienti enaka. Podatke imamo za 115 pacientov, vsak od njih pa ima do 35 merjenj.


```{r}
pod.Lng <- dt %>%
  group_by(AnonId) %>%
  summarise(povprecje = mean(Lng), n=length(Lng), varianca = var(Lng))

```


```{r, fig.width=6, fig.height=4,fig.align="center"}
ggplot(dt, aes(x = AnonId, y = Lng, group = AnonId))+
  stat_summary(fun.ymin = min, fun.ymax = max, fun.y = mean) + 
  theme(axis.text.x =element_text(color = "white"))+
  labs(x = "Pacienti", y = "Premik" )+
  ggtitle("Povprecja premikov pacientov v longitudinalni smeri")
```

```{r}
m <- length(pod.Lng$AnonId)
n <- pod.Lng$n
ime.unique <- levels(dt$AnonId)

xMatrix <- matrix(NA, ncol = m, nrow = max(n))
for (j in 1:m) {
  xMatrix[1:n[j],j] <- dt[dt$AnonId == ime.unique[j],]$Lng - mean(dt[dt$AnonId == ime.unique[j],]$Lng) #centriramo
}
```

Določil sem tudi parametre hiperapriornih porazdelitev:
\begin{align*}
\sigma^2 &\sim \text{Inv-Gama}(\nu_0 / 2, \sigma_0^2 \nu_0 / 2), \\
\mu &\sim \mathcal{N}(\mu_0, \tau_0^2), \\
\eta^2 &\sim \text{Inv-Gama}(\kappa_0 / 2, \eta_0^2 \kappa_0 / 2).
\end{align*}

```{r nimbleCode}
code <- nimbleCode({
  mu ~ dnorm(0, sd = 10);
  eta ~ dunif(0, 100)
  sigma ~ dunif(0, 100)

  for (j in 1:m) {
    muGroups[j] ~ dnorm(mu, sd = eta)
    for (i in 1:n[j]) {
      y[i, j] ~ dnorm(muGroups[j], sd = sigma);
    }
  }
})
```

Ker je želja, da bi bili premiki med opazovanjem čim manjši, kar pomeni, da je pričakovana vrednost radioterapije enaka 0. Za standardni odklon sem preizkusil več vrednosti, nato sem se odločil za 1. Med podatki ni nikoli vrednosti višje od 2, vednar sem želel biti previden in si nisem želel preveč omejevati.
Parametra $\eta$ in $\sigma$ sem vzorčil iz enakomerne porazdelitve 0 - 10. Pri tem sem poskusil, tudi širše intervale, vendar so se mi tukaj rezultati zdeli najbolj optimalni.


```{r HieModel, eval=FALSE, message=FALSE, warning=FALSE}
constants <- list(m = m, n = n)

inits <- list(mu = mean(pod.Lng$povprecje),
              eta = sd(pod.Lng$povprecje),
              sigma = mean(sqrt(pod.Lng$varianca)),
              muGroups = pod.Lng$povprecje)

data <- list(y = xMatrix)

Rmodel <- nimbleModel(code = code, constants = constants,
                      inits = inits, data = data)
Rmodel$initializeInfo()

conf <- configureMCMC(Rmodel)
#conf$printSamplers()
#conf$printMonitors()
conf$addMonitors('muGroups')

Rmcmc <- buildMCMC(conf)
Cmodel <- compileNimble(Rmodel)
Cmcmc <- compileNimble(Rmcmc, project = Cmodel)
samples <- runMCMC(Cmcmc, niter = 12000, nburnin = 2000 )
#saveRDS(samples, "data/HieMod.RDS")
```


### Konvergenca
Najprej sem preučil konvergenco parametrov in naključno izbranega pacienta.

```{r}
par(mfrow = c(2,2))
plot(samples[,2], type = "l", main = "mu")
plot(samples[,44], type = "l", main = "Pacient 42")
plot(samples[,1], type = "l", main = "eta")
plot(samples[,118], type = "l", main = "sigma")
```

Z konvergenco izgleda vse ok, saj so vrednosti na y-osi dovolj male. Pozorni moramo biti, saj so vrednosti merjenja majhne in da ne pride do prevelikih odstopanj.

### Thinning

Ker v MCMC verigah prevladuje visoka stopnja avtokorelacije, zato je potrebna analiza tudi v mojem primeru.

```{r, fig.width=6, fig.height=4,fig.align="center"}
par(mfrow = c(2,2))
acf(samples[,2], main = "mu")
acf(samples[,44])
acf(samples[,1])
acf(samples[,118])
```

Kot vidimo so podatki v MCMC verigi visoko korelirani, zato moramo uporabiti thinning. Koliko vrednosti bomo spusitli vmes je odvisno od podatkov, zato sem to storil s poskušanjem. Na koncu sem se odločil za 300 in se s tem rešil avtokorelacije. (Ne vem ali je to prevelika številka v praksi in bi moral drugače postopati).

Na novo definiramo model in temu primerno povečamo število iteracij in burn-in.

```{r HiModelThinning, eval=FALSE, message=FALSE, warning=FALSE}
samples.thinning <- samples <- runMCMC(Cmcmc, niter = 120000, nburnin = 20000, thin =300)
#saveRDS(samples.thinning, "data/HieMod_thinning.RDS")
```

in najprej pogledamo thinning:

```{r, fig.width=6, fig.height=4,fig.align="center"}
par(mfrow = c(2,2))
acf(samples.thinning[,2], main = "mu")
acf(samples.thinning[,44], main = "mu_42")
acf(samples.thinning[,1], main = "eta")
acf(samples.thinning[,118], main = "sigma")
```

Še vedno ni videti vredu, saj nekateri saj so ostanki po lagih še vedno večji od 95 \% intervala zaupanja, ki je narisan s črtkano črto. Vseeno nadaljujem z analizo.

Še enkrat sem pogledal konvergenco za končni model (s thinningom):

```{r, fig.width=4, fig.height=2,fig.align="center"}
samplesPlot(samples.thinning, var = c("mu","muGroups[42]"))
kable(samplesSummary(samples.thinning)[c(2, 44), ], "markdown")
```

Glede na skalo, ki je na y-osi, bi rekel, da je konvergenca spremenljiva, čeprav graf od daleč zgleda da zelo variara.

```{r, fig.width=4, fig.height=2,fig.align="center"}
samplesPlot(samples.thinning, var = c("eta","sigma"))
kable(samplesSummary(samples.thinning)[c(1, 118), ], "markdown")
```

Za parametra $\sigma$ in $\eta$ je konvergenca vredu. Posteriorne porazdelitve $\eta$ dosegajo vrednosti zelo blizu, medtem ko porazdelitev parametra $\sigma$ malce odmaknjena od 0, s povprečjem 0.15.

### Efective size in standardna napaka

```{r}
efektivni.vzorec<- effectiveSize(samples.thinning)
moj.efect.vzorec <- efektivni.vzorec[c(1,2,44,118)]
sd.vzorec <- apply(samples.thinning[,c(1,2,44,118)], 2, sd)
standardne.napake <- sapply(1:4, function(i){sd.vzorec[i]/sqrt(moj.efect.vzorec[i])})

kable(data.frame("Effective size" = moj.efect.vzorec, "Standardna napaka" = standardne.napake), "markdown")
```

Efektivna velikost vzorca se giblje okoli 100 za posameznega pacienta. Za hiper parameter $\sigma$ pa okoli 333. Standardne napake so za vse parametre zelo majhne, kar je dober znak za model.


### Marginalne aposteriorne porazdelitve

```{r MarginalnePorazd, fig.width=6, fig.height=4,fig.align="center"}
par(mfrow=c(2, 2))
plot(density(samples.thinning[ , 2]), type = "l", main = "mu")
abline(v = quantile(samples.thinning[ , 2], prob=c(0.025, 0.5, 0.975)), lty = 2)
plot(density(samples.thinning[ , 1]**2), type = "l", main = "eta2")
abline(v = quantile(samples.thinning[ , 1]**2, prob=c(0.025, 0.5, 0.975)), lty = 2)
plot(density(samples.thinning[ , 44]), type = "l", main = "mu_42")
abline(v = quantile(samples.thinning[ , 3], prob=c(0.025, 0.5, 0.975)), lty = 2)
plot(density(samples.thinning[ , 118]**2), type = "l", main = "sigma2")
abline(v = quantile(samples.thinning[ , 118]**2, prob=c(0.025, 0.5, 0.975)), lty = 2)

```

Model za parameter $\mu$ daje zelo optimistične napovedi, saj pravi, da bo skupno povprečje vseh pacientov znašalo zelo blizu 0. Paramater $\eta$ je zelo blizu 0. 95 \% interval zaupnja za $\sigma^2$ je 0.022 in 0.248, kar kaže na to, da bodo odstopanja od povprečja zelo majhne pri vseh pacientih v modelu. Tako se izkaže tudi pri primeru enega od pacientov, ki ima povprečje pri 0.0003.


Posebaj sem pogledal primer za dva pacienta. Izbrana sta pacienta, ki sta imela največjo in najmanjšo razliko med vzorčnim povprečj in 0. To sta: največjo (76. pacient) in najmanjšo (92.pacient).

```{r dvaPacienta,  fig.width=6, fig.height=4,fig.align="center"}
plot(density(samples.thinning[,19]), type="l", main="")
points(pod.Lng[19,]$povprecje, 2, pch=16, cex=1.5, col="red")
abline(v = mean(samples.thinning[,19]), lty=2)
lines(density(samples.thinning[,44]), type="l", col="red")
points(pod.Lng[44,]$povprecje, 2, pch=16, cex=1.5, col="red")
abline(v = mean(samples.thinning[,44]), lty=2, col="red")
abline(v = mean(samples.thinning[,2]), lty=2, col="green3")
legend("topleft", c("92. pacient", "njeno vz. povp.", "njen E(apost)", 
                    "76. pacient", "njeno vz. povp.", "njen E(apost)"), 
       col=c("black","black","black","red","red","red"), lty=c(1,NA,2,1,NA,2), 
       pch=c(NA,16,NA,NA,16,NA))
```
 
Posteriorni porazdelitvi se nekoliko razlikjueta, njuna modelska povprečja $\mu_43$ in $\mu_6$ omejujeta modelsko skupno poveprečje (zelena črtkana črta). Vzorčno povprečje za $\mu_43 = 0.7$ je tako daleč stran, modelske napovedi, da ju na grafu ni mogoče narisati.

```{r, fig.width=6, fig.height=4,fig.align="center"}
pod.Lng$EMuGroup <- colMeans(samples.thinning[,3:117])

par(mfrow=c(1,2))
plot(pod.Lng$povprecje, pod.Lng$EMuGroup,
     xlab = "vzorcno povprecje", ylab = expression(E(mu_j)))
abline(a = 0, b = 1)

plot(pod.Lng$n, pod.Lng$povprecje - pod.Lng$EMuGroup,
     xlab = "velikost vzorca sole", 
     ylab = expression(paste("vzorcno povprecje - "," ",E(mu_j), sep="")))
abline(h = 0)
```

Na levi sliki je predstavljeno pričakovana vrednost model za vsakega pacienta v primerjavi z vzorčnim povprečjem vsakega pacienta. Sam menim, da model ne predstavlja dobro podatkov, saj o ocenjuje napako zelo blizu 0 (povečanje apriorne porazdelitve ne pomaga kaj dosti), vzorčna pa se raztezajo od -0.2 do 0.8. Črta predstavlja kako dobro se vzorčna povprečja ujemajo z modelom.

Desna slika predstavlja vpliv velikosti vzorca na razliko vzorčnege poveprečja j-tega pacienta z njegovo pričakovano vrednostjo modela. Vidimo, da je število obsevanj ne vpliva na minimiziranje razlik med podatki in modelom. To je seveda logična posledica, saj so merjenja med seboj popolnoma neodivsna in več merjenj ne bo dalo manjših premikov pacienta. Po drugi strani pa pacienta med obsevanji večkrat slikajo in nato prilagodijo njegov novi položaj, kar posledično pomeni, da bi se napaka morala zmanjševat. Vendar podatkov o tem, kdaj mu na novo izračunajo položaj nimam.

Zakaj je prišlo do tega? Po mojem mnenju zato, ker sem model gradil na osnovni predpostavki, da so variance med pacienti enake. Mislim, da je to glavni razlog zakaj se modelske napovedi ne ujemajo z vzorčnimi povprečji.  



# Priloga

V prilogi so grafi in opombe za vsak simulacijski scenarij, kjer smo uporabili bayesx funkcijo.

## Scenarij I
```{r}
data.N1 <- gen.beta.data(100, napaka = rnorm(100))
bayesx.norm <- bayesx(y ~ X1+X2+X3+X4+X5 , data = data.N1, 
                        family = "gaussian", method = "MCMC")
bayesx.mu <- attr(bayesx.norm$fixed.effects, "sample")
```

### Thinning
```{r}
par(mfrow= c(2,3))
acf(bayesx.mu[,1], main = "beta_0")
acf(bayesx.mu[,2],main = "beta_1")
acf(bayesx.mu[,3],main = "beta_2")
acf(bayesx.mu[,4],main = "beta_3")
acf(bayesx.mu[,5],main = "beta_4")
acf(bayesx.mu[,6],main = "beta_5")
```

### Burn-in

```{r}
par(mfrow= c(2,3))
plot(bayesx.mu[,1], type = "l", main = "beta_0")
plot(bayesx.mu[,2], type = "l", main = "beta_1")
plot(bayesx.mu[,3], type = "l", main = "beta_2")
plot(bayesx.mu[,4], type = "l", main = "beta_3")
plot(bayesx.mu[,5], type = "l", main = "beta_4")
plot(bayesx.mu[,6], type = "l", main = "beta_5")
```


## Scenarij II
```{r}
data.N3 <- gen.beta.data(100, napaka = rnorm(100,0,3))
bayesx.norm <- bayesx(y ~ X1+X2+X3+X4+X5 , data = data.N3, 
                        family = "gaussian", method = "MCMC")
bayesx.mu <- attr(bayesx.norm$fixed.effects, "sample")
```

### Thinning
```{r}
par(mfrow= c(2,3))
acf(bayesx.mu[,1], main = "beta_0")
acf(bayesx.mu[,2],main = "beta_1")
acf(bayesx.mu[,3],main = "beta_2")
acf(bayesx.mu[,4],main = "beta_3")
acf(bayesx.mu[,5],main = "beta_4")
acf(bayesx.mu[,6],main = "beta_5")
```

### Burn-in

```{r}
par(mfrow= c(2,3))
plot(bayesx.mu[,1], type = "l", main = "beta_0")
plot(bayesx.mu[,2], type = "l", main = "beta_1")
plot(bayesx.mu[,3], type = "l", main = "beta_2")
plot(bayesx.mu[,4], type = "l", main = "beta_3")
plot(bayesx.mu[,5], type = "l", main = "beta_4")
plot(bayesx.mu[,6], type = "l", main = "beta_5")
```


## Scenarij III
```{r}
data.H1 <- gen.beta.data(100, napaka = rchisq(100, 1))
bayesx.norm <- bayesx(y ~ X1+X2+X3+X4+X5 , data = data.H1, 
                        family = "gaussian", method = "MCMC")
bayesx.mu <- attr(bayesx.norm$fixed.effects, "sample")
```

### Thinning
```{r}
par(mfrow= c(2,3))
acf(bayesx.mu[,1], main = "beta_0")
acf(bayesx.mu[,2],main = "beta_1")
acf(bayesx.mu[,3],main = "beta_2")
acf(bayesx.mu[,4],main = "beta_3")
acf(bayesx.mu[,5],main = "beta_4")
acf(bayesx.mu[,6],main = "beta_5")
```

### Burn-in

```{r}
par(mfrow= c(2,3))
plot(bayesx.mu[,1], type = "l", main = "beta_0")
plot(bayesx.mu[,2], type = "l", main = "beta_1")
plot(bayesx.mu[,3], type = "l", main = "beta_2")
plot(bayesx.mu[,4], type = "l", main = "beta_3")
plot(bayesx.mu[,5], type = "l", main = "beta_4")
plot(bayesx.mu[,6], type = "l", main = "beta_5")
```


### Scenarij IV
```{r}
data.H4 <- gen.beta.data(100, napaka = rchisq(100, 4))
bayesx.norm <- bayesx(y ~ X1+X2+X3+X4+X5 , data = data.H4, 
                        family = "gaussian", method = "MCMC")
bayesx.mu <- attr(bayesx.norm$fixed.effects, "sample")
```

### Thinning
```{r}
par(mfrow= c(2,3))
acf(bayesx.mu[,1], main = "beta_0")
acf(bayesx.mu[,2],main = "beta_1")
acf(bayesx.mu[,3],main = "beta_2")
acf(bayesx.mu[,4],main = "beta_3")
acf(bayesx.mu[,5],main = "beta_4")
acf(bayesx.mu[,6],main = "beta_5")
```

### Burn-in

```{r}
par(mfrow= c(2,3))
plot(bayesx.mu[,1], type = "l", main = "beta_0")
plot(bayesx.mu[,2], type = "l", main = "beta_1")
plot(bayesx.mu[,3], type = "l", main = "beta_2")
plot(bayesx.mu[,4], type = "l", main = "beta_3")
plot(bayesx.mu[,5], type = "l", main = "beta_4")
plot(bayesx.mu[,6], type = "l", main = "beta_5")
```


